{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nedac23/Machine-Learning/blob/main/MLHW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:"
      ],
      "metadata": {
        "id": "rFXVDslTEdZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu3FS7qLmLwA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute mean and variance, 5 points\n",
        "def mean_variance(X):\n",
        "  #gets the mean and vairence for each pixel\n",
        "    mean = np.mean(X, axis=0)\n",
        "    variance = np.var(X, axis=0)\n",
        "    return mean, variance"
      ],
      "metadata": {
        "id": "svM1Zke4mhGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOT USED\n",
        "#def gaussian_pdf(x, mean, var):\n",
        "   # l = (1 / (np.sqrt(var) * np.sqrt(2 * np.pi))) * np.exp(-((x - mean) ** 2) / (2 * var))\n",
        "    #return l"
      ],
      "metadata": {
        "id": "XmZOIGNOmo6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute Gaussian probability density, 5 points\n",
        "#uses guassina pdf but instead of how its used in class logs are used to prevent underflwo error\n",
        "#when using the above one I had a very low accucary of around 9% which didnt make sense untill i discovered underflow error\n",
        "def gaussian_log_pdf(x, mean, var):\n",
        "    var = np.maximum(var, 1e-6)  # Ensure variance is never zero\n",
        "    return -0.5 * (np.log(2 * np.pi * var) + ((x - mean) ** 2) / var)"
      ],
      "metadata": {
        "id": "ugHtPojAAvUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute priors, 5 points\n",
        "def compute_priors(y):\n",
        "    classes, counts = np.unique(y, return_counts=True)\n",
        "    priors = counts / len(y)\n",
        "    return priors"
      ],
      "metadata": {
        "id": "7h4n02zvmgyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Prediction, 10 points\n",
        "# def predict(X, Y, means, variances, priors):\n",
        "\n",
        "#     # m = {}\n",
        "#     # j = 0\n",
        "#     predictions = []\n",
        "#     for x in X:\n",
        "#       # pred = {}\n",
        "#       # n = {}\n",
        "#       # dist = 1\n",
        "#       class_likelihoods = []\n",
        "#       for i in range(10):\n",
        "#         likelihood = priors[i]\n",
        "#         # for p in range(len(x)):\n",
        "#         #   dist = gaussian_pdf(x,means[i],variances[i]) * dist\n",
        "#         #   like = dist * priors[i]\n",
        "#         #   pred[p] = like\n",
        "#         # n[i] = np.argmax(list(pred.values()))\n",
        "#         # pred.clear()\n",
        "\n",
        "#         for p in range(len(x)):  # For each pixel\n",
        "#           likelihood *= gaussian_pdf(x[p], means[i][p], variances[i][p])\n",
        "#         class_likelihoods.append(likelihood)\n",
        "#       predicted_class = np.argmax(class_likelihoods)\n",
        "#       predictions.append(predicted_class)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#       # final = np.argmax(list(n.values()))\n",
        "#       # m[j] = final\n",
        "#       # pred.clear()\n",
        "#       # j = j + 1\n",
        "\n",
        "#     #return np.array(list(m.values()))\n",
        "#     return np.array(predictions)"
      ],
      "metadata": {
        "id": "PXxJdmsgmgpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction, 10 points\n",
        "def predict_log(X, means, variances, priors):\n",
        "    #ChatGpt was used to discover an issue with underflow values causing a low accuacy.\n",
        "    #This code addresses this by using logarithm calculations rather than the above funciton.\n",
        "    predictions = []\n",
        "\n",
        "    for x in X:  # For each image\n",
        "        class_log_likelihoods = []\n",
        "\n",
        "        for i in range(10):  # For each class\n",
        "            log_likelihood = np.log(priors[i])\n",
        "            for p in range(len(x)):  # For each pixel\n",
        "                log_likelihood += gaussian_log_pdf(x[p], means[i][p], variances[i][p])\n",
        "            class_log_likelihoods.append(log_likelihood)\n",
        "\n",
        "        predicted_class = np.argmax(class_log_likelihoods)\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "    return np.array(predictions)"
      ],
      "metadata": {
        "id": "e91W0WIxA3pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#print(len(y_train))\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Dki7Wc3Dmgbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training: Compute mean, variance, and priors for each class\n",
        "means = {}\n",
        "variances = {}\n",
        "priors = compute_priors(y_train)\n",
        "#priors is  an ordered array of the prior prob of each class\n",
        "print(len(X_train_scaled))\n",
        "print(len(y_train))\n",
        "for c in np.unique(y_train):\n",
        "  X_c = X_train_scaled[y_train == c]\n",
        "  #print(c)\n",
        "  print(len(X_c))\n",
        "  #c is the number it is labeled as so for ex. 0 - 9\n",
        "  # X_c is the data for that particluar number\n",
        "  #print(X_c)\n",
        "  means[c], variances[c] = mean_variance(X_c)\n",
        "  print(f\"Class {c} Mean Shape: {means[c].shape}, Variance Shape: {variances[c].shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSDJFqTymzW2",
        "outputId": "12e99ada-e61d-402c-aa6c-f958db0a45d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1437\n",
            "1437\n",
            "145\n",
            "Class 0 Mean Shape: (64,), Variance Shape: (64,)\n",
            "154\n",
            "Class 1 Mean Shape: (64,), Variance Shape: (64,)\n",
            "144\n",
            "Class 2 Mean Shape: (64,), Variance Shape: (64,)\n",
            "149\n",
            "Class 3 Mean Shape: (64,), Variance Shape: (64,)\n",
            "135\n",
            "Class 4 Mean Shape: (64,), Variance Shape: (64,)\n",
            "135\n",
            "Class 5 Mean Shape: (64,), Variance Shape: (64,)\n",
            "146\n",
            "Class 6 Mean Shape: (64,), Variance Shape: (64,)\n",
            "145\n",
            "Class 7 Mean Shape: (64,), Variance Shape: (64,)\n",
            "144\n",
            "Class 8 Mean Shape: (64,), Variance Shape: (64,)\n",
            "140\n",
            "Class 9 Mean Shape: (64,), Variance Shape: (64,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on scaled data\n",
        "y_pred_scaled = predict_log(X_test_scaled, means,variances,priors)\n",
        "print(len(X_test_scaled))\n",
        "print(len(y_pred_scaled))\n",
        "print(len(y_test))\n",
        "\n",
        "accuracy_scaled = np.mean(y_pred_scaled == y_test)\n",
        "# Evaluation\n",
        "print(f\"Accuracy after scaling: {accuracy_scaled:.4f}\")\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_scaled)\n",
        "f1_micro = f1_score(y_test, y_pred_scaled, average='micro')\n",
        "f1_macro = f1_score(y_test, y_pred_scaled, average='macro')\n",
        "f1_weighted = f1_score(y_test, y_pred_scaled, average='weighted')\n",
        "\n",
        "precision_micro = precision_score(y_test, y_pred_scaled, average='micro')\n",
        "precision_macro = precision_score(y_test, y_pred_scaled, average='macro')\n",
        "precision_weighted = precision_score(y_test, y_pred_scaled, average='weighted')\n",
        "\n",
        "recall_micro = recall_score(y_test, y_pred_scaled, average='micro')\n",
        "recall_macro = recall_score(y_test, y_pred_scaled, average='macro')\n",
        "recall_weighted = recall_score(y_test, y_pred_scaled, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cowDTwcDm2KV",
        "outputId": "82e0bb1a-7d72-4693-af53-adfc8657c639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n",
            "360\n",
            "360\n",
            "Accuracy after scaling: 0.8528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "print(\"\\nF1 Scores:\")\n",
        "print(f\"Micro: {f1_micro:.4f}\")\n",
        "print(f\"Macro: {f1_macro:.4f}\")\n",
        "print(f\"Weighted: {f1_weighted:.4f}\")\n",
        "\n",
        "print(\"\\nPrecision Scores:\")\n",
        "print(f\"Micro: {precision_micro:.4f}\")\n",
        "print(f\"Macro: {precision_macro:.4f}\")\n",
        "print(f\"Weighted: {precision_weighted:.4f}\")\n",
        "\n",
        "print(\"\\nRecall Scores:\")\n",
        "print(f\"Micro: {recall_micro:.4f}\")\n",
        "print(f\"Macro: {recall_macro:.4f}\")\n",
        "print(f\"Weighted: {recall_weighted:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZxyEl9Dm8ZK",
        "outputId": "d1f4f861-d1a1-4404-a7ea-fc0ee45e6079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[31  0  0  0  0  1  0  1  0  0]\n",
            " [ 0 22  0  0  0  0  0  0  4  2]\n",
            " [ 0  2 20  1  0  0  1  0  9  0]\n",
            " [ 0  0  1 30  0  1  0  0  2  0]\n",
            " [ 0  0  0  0 37  0  2  7  0  0]\n",
            " [ 0  0  0  1  0 44  1  1  0  0]\n",
            " [ 0  0  0  0  0  0 35  0  0  0]\n",
            " [ 0  0  0  0  0  1  0 33  0  0]\n",
            " [ 0  1  0  0  0  0  0  2 27  0]\n",
            " [ 0  1  1  1  0  2  0  3  4 28]]\n",
            "\n",
            "F1 Scores:\n",
            "Micro: 0.8528\n",
            "Macro: 0.8486\n",
            "Weighted: 0.8540\n",
            "\n",
            "Precision Scores:\n",
            "Micro: 0.8528\n",
            "Macro: 0.8682\n",
            "Weighted: 0.8779\n",
            "\n",
            "Recall Scores:\n",
            "Micro: 0.8528\n",
            "Macro: 0.8525\n",
            "Weighted: 0.8528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2:"
      ],
      "metadata": {
        "id": "RavTD1NMEZ8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "QLW5Ot_3Ei0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MixedNB:\n",
        "  #chatgpt was used to help flesh out the structure of the class\n",
        "  #it was used to help understand and find the best implementation method for parts of the fit and predict functions.\n",
        "    def __init__(self):\n",
        "      self.class_probs = None\n",
        "      self.continuous = {}\n",
        "      self.categorical = {}\n",
        "\n",
        "\n",
        "    def fit(self, X, y, continuous_features):\n",
        "     #priors\n",
        "      classes, counts = np.unique(y, return_counts=True)\n",
        "      priors = counts / len(y)\n",
        "      self.class_probs = priors\n",
        "\n",
        "      #intializing dictionaries to store mean and var and propabilites for categories\n",
        "      #intializes number of samels and features based on X the data\n",
        "      samples, features = X.shape\n",
        "      self.continuous = {}\n",
        "      self.categorical = {}\n",
        "\n",
        "      #means and var for contuinous to be used in guassina\n",
        "      for con in continuous_features:\n",
        "          self.continuous[con] = {}\n",
        "          for c in np.unique(y):\n",
        "            #gets value for that calss and feature\n",
        "              vals = X[y == c, con]\n",
        "              #sets mean var for each to be used later in guassian\n",
        "              self.continuous[con][c] = {\n",
        "                  'mean': np.mean(vals),\n",
        "                  'variance': np.var(vals)\n",
        "              }\n",
        "\n",
        "      #finds categorical features from the X and conti lists\n",
        "      categorical_features = [i for i in range(features) if i not in continuous_features]\n",
        "      #categorical_features = np.setdiff1d(X,continuous_features, assume_unique=False)\n",
        "      for cat in categorical_features:\n",
        "          self.categorical[cat] = {}\n",
        "          for c in np.unique(y):\n",
        "            #gets value for that calss and feature\n",
        "              vals = X[y == c, cat]\n",
        "              #calcules probaboilities in the same was as proirs for each val\n",
        "              unique_values, counts = np.unique(vals, return_counts=True)\n",
        "              probs = counts / counts.sum()\n",
        "              #adds to probs for categories\n",
        "              self.categorical[cat][c] = (unique_values, probs)\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "      samples = X.shape[0]\n",
        "      predictions = []\n",
        "\n",
        "      for i in range(samples):\n",
        "        #for each sample\n",
        "          sample = X[i]\n",
        "          class_log_probs = []\n",
        "\n",
        "          for cIdx, cProb in enumerate(self.class_probs):\n",
        "            #for each class and probability\n",
        "            #using logs to account for underflow\n",
        "              log_prob = np.log(cProb)\n",
        "\n",
        "              for feature, value in enumerate(sample):\n",
        "                  #for each feature and value\n",
        "                  #if contious\n",
        "                  if feature in self.continuous:\n",
        "                      if cIdx in self.continuous[feature]:\n",
        "                        #pulls the mean and vairence for the feature in the class\n",
        "                          params = self.continuous[feature][cIdx]\n",
        "                          mean = params['mean']\n",
        "                          var = params['variance']\n",
        "                          if var <= 0:\n",
        "                            var = 1e-6\n",
        "\n",
        "                          #caluating guassinan\n",
        "                          log_likelihood = -0.5 * np.log(2 * np.pi * var) - ((value - mean) ** 2) / (2 * var)\n",
        "                          log_prob += log_likelihood\n",
        "\n",
        "                  # category\n",
        "                  else:\n",
        "                      if cIdx in self.categorical[feature]:\n",
        "                          categories, probs = self.categorical[feature][cIdx]\n",
        "                          #pulls the probability and category for the feature in the class\n",
        "                          if value in categories:\n",
        "                            matching_index = np.where(categories == value)[0][0]\n",
        "                            prob = probs[matching_index]\n",
        "                          else:\n",
        "                            #prob is small\n",
        "                              prob = 1e-10\n",
        "                          log_prob += np.log(prob)\n",
        "              #adds probabilities\n",
        "              class_log_probs.append(log_prob)\n",
        "\n",
        "          #predicts best class\n",
        "          predictions.append(np.argmax(class_log_probs))\n",
        "\n",
        "      return np.array(predictions)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T1J3weRnKf3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "adult = fetch_openml(name='adult', version=2)\n",
        "X, y = adult.data, adult.target\n",
        "\n",
        "# Convert to DataFrame for easier preprocessing\n",
        "X_df = pd.DataFrame(X, columns=adult.feature_names)\n",
        "y_encoded = LabelEncoder().fit_transform(y)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns)\n",
        "\n",
        "# Encode categorical variables\n",
        "X_df_encoded = X_df_imputed.apply(lambda col: LabelEncoder().fit_transform(col.astype(str)) if col.dtype.name == 'category' or col.dtype == object else col)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df_encoded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Identify continuous features\n",
        "continuous_features = [i for i, col in enumerate(X_df.columns) if X_df[col].dtype.name != 'category' and X_df[col].dtype != object]"
      ],
      "metadata": {
        "id": "mHyQNNkJKiRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and train the model\n",
        "model = MixedNB()\n",
        "model.fit(X_train.values, y_train, continuous_features=continuous_features)"
      ],
      "metadata": {
        "id": "qUw4cCB-KzHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test.values)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI7lHBoNKzho",
        "outputId": "476168ce-1af7-42fa-9c9c-46894fb8685d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculations\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
        "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
        "precision_weighted = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
        "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
        "recall_weighted = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Display the results\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "print(\"\\nF1 Scores:\")\n",
        "print(f\"Micro: {f1_micro:.4f}\")\n",
        "print(f\"Macro: {f1_macro:.4f}\")\n",
        "print(f\"Weighted: {f1_weighted:.4f}\")\n",
        "\n",
        "print(\"\\nPrecision Scores:\")\n",
        "print(f\"Micro: {precision_micro:.4f}\")\n",
        "print(f\"Macro: {precision_macro:.4f}\")\n",
        "print(f\"Weighted: {precision_weighted:.4f}\")\n",
        "\n",
        "print(\"\\nRecall Scores:\")\n",
        "print(f\"Micro: {recall_micro:.4f}\")\n",
        "print(f\"Macro: {recall_macro:.4f}\")\n",
        "print(f\"Weighted: {recall_weighted:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHdvjSj9K54n",
        "outputId": "7b597094-8901-41f6-ba03-e966a413e0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[6676  803]\n",
            " [ 864 1426]]\n",
            "\n",
            "F1 Scores:\n",
            "Micro: 0.8294\n",
            "Macro: 0.7601\n",
            "Weighted: 0.8286\n",
            "\n",
            "Precision Scores:\n",
            "Micro: 0.8294\n",
            "Macro: 0.7626\n",
            "Weighted: 0.8278\n",
            "\n",
            "Recall Scores:\n",
            "Micro: 0.8294\n",
            "Macro: 0.7577\n",
            "Weighted: 0.8294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References and AI Usage:\n",
        "\n",
        "http://numpy.org/doc/2.2/index.html\n",
        "\n",
        "The author acknowledges the use of ChatGPT in the preparation of this assignment to brainstorm and understand approaches to the problems and better understand the content. ChatGPT was used to help understand and implement parts of the Naive Bayes classifier."
      ],
      "metadata": {
        "id": "5xdgVyEq-MSb"
      }
    }
  ]
}